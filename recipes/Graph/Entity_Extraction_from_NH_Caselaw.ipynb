{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Entity Extraction from New Hampshire Case Law\n",
    "*With IBM Granite Models*\n",
    "\n",
    "The [New Hampshire Case Law Dataset](https://huggingface.co/datasets/free-law/nh) comes from the Caselaw Access Project via Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook\n",
    "This notebook contains instructions for performing entity extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To get started, you'll need:\n",
    "* A [Replicate account](https://replicate.com/) and API token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "Granite Kitchen comes with a bundle of dependencies that are required for notebooks. See the list of packages in its [`setup.py`](https://github.com/ibm-granite-community/granite-kitchen/blob/main/setup.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    \"langchain_community<0.3.0\" \\\n",
    "    replicate \\\n",
    "    datasets \\\n",
    "    transformers \\\n",
    "    tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting System Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Choose your LLM\n",
    "The LLM will be used for answering the question, given the retrieved text.\n",
    "\n",
    "Follow the instructions in [Getting Started with Replicate](https://github.com/ibm-granite-community/granite-kitchen/blob/cee1513c77429d7ddbf0e5a49b29b7bc9ca0d996/recipes/Getting_Started/Getting_Started_with_Replicate.ipynb), selecting a Granite Code model from the [`ibm-granite`](https://replicate.com/ibm-granite) org.\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "from ibm_granite_community.notebook_utils import set_env_var\n",
    "\n",
    "set_env_var(\"REPLICATE_API_TOKEN\")\n",
    "\n",
    "model = Replicate(\n",
    "    model=\"ibm-granite/granite-3.0-8b-instruct\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the tokenizer\n",
    "\n",
    "Retrieve the tokenizer used by your chosen LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.0-8b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring the Data\n",
    "\n",
    "We will use a New Hampshire case law dataset to help the model answer questions about NH laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the documents\n",
    "\n",
    "Download the [New Hampshire CAP Caselaw](https://huggingface.co/datasets/free-law/nh) dataset from HuggingFace using the datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "\n",
    "# Load the documents from the dataset\n",
    "loader = HuggingFaceDatasetLoader(\"free-law/nh\", page_content_column=\"text\")\n",
    "documents = loader.load()\n",
    "print(\"Document Count: \" + str(len(documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add metadata to the documents\n",
    "\n",
    "Add the `source` field, which is used below, to the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    doc.metadata['source'] = doc.metadata['id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents[:1]:\n",
    "    print(doc.metadata, \"\\n\")\n",
    "    print(doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Document Database\n",
    "\n",
    "We'll use the caselaw document database to retrieve the full text of the cases by case id."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the database file and document table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # put the json objects in a sqlite database, keyed by id\n",
    "# import sqlite3, os, json\n",
    "\n",
    "# # remove database file if exists\n",
    "# if os.path.isfile('data.db'):\n",
    "#     os.remove('data.db')\n",
    "\n",
    "# conn = sqlite3.connect('data.db')\n",
    "# c = conn.cursor()\n",
    "\n",
    "# # create the table if it doesn't exist. include id, text, and size\n",
    "# c.execute('''CREATE TABLE IF NOT EXISTS data\n",
    "#              (id INTEGER PRIMARY KEY UNIQUE,\n",
    "#               metadata TEXT,\n",
    "#               text TEXT,\n",
    "#               char_count INTEGER)''')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the documents into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for doc in documents:\n",
    "#     id = doc.metadata[\"id\"]\n",
    "#     c.execute(\"INSERT INTO data (id, metadata, text, char_count) VALUES (?,?,?,?)\", (id, json.dumps(doc.metadata), doc.page_content, doc.metadata[\"char_count\"]))\n",
    "#     conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c.execute(\"SELECT count(*) FROM data\")\n",
    "# doc_count = c.fetchone()[0]\n",
    "# print(f\"Document count: {doc_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the entities\n",
    "\n",
    "In this example, we take the caselaw text, split it into chunks, and extract entities from each chunk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the document into chunks\n",
    "\n",
    "Split the document into text segments that can fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=10)\n",
    "chunks = text_splitter.split_documents(documents[:1])\n",
    "print(\"Chunk Count: \" + str(len(chunks)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for i in range(1):\n",
    "    print(chunks[i].page_content)\n",
    "    print(json.dumps(chunks[i].metadata, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide taxonomy of entities\n",
    "\n",
    "An LLM may produce this with the prompt:\n",
    "\n",
    "```\n",
    "I am building a knowledge graph from legal case law. What are the entities I should extract for this knowledge graph?\n",
    "Prefix the major categories with numbers, and the minor categories with letters.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"\n",
    "Here are the categories of entity I want you to consider:\n",
    "\n",
    "1. Case Information:\n",
    "A. Case Name (e.g., \"Brown v. Board of Education\")\n",
    "B. Docket Number (unique case identifier)\n",
    "C. Court (e.g., Supreme Court, District Court)\n",
    "D. Jurisdiction (state or federal jurisdiction, e.g., California, United States)\n",
    "2. Legal Parties:\n",
    "A. Plaintiff/Petitioner (the party initiating the case)\n",
    "B. Defendant/Respondent (the party responding to the case)\n",
    "C. Appellant/Appellee (for appeals)\n",
    "3. Attorneys:\n",
    "A. Counsel for Plaintiff/Petitioner (name, law firm, or organization)\n",
    "B. Counsel for Defendant/Respondent (name, law firm, or organization)\n",
    "4. Judges:\n",
    "A. Judge(s)/Justice(s) (name and role: trial judge, appellate judge, presiding justice)\n",
    "B. Panel Composition (for appellate cases, listing judges involved)\n",
    "5. Legal Issues:\n",
    "A. Legal Questions (the issues or questions of law presented to the court)\n",
    "B. Claims (the specific claims or complaints raised by the plaintiff)\n",
    "6. Legal Doctrines and Principles:\n",
    "A. Statutes/Acts (e.g., \"Civil Rights Act of 1964\")\n",
    "B. Precedents Cited (previous case law referred to)\n",
    "C. Constitutional Provisions (e.g., \"First Amendment,\" \"Article III\")\n",
    "7. Facts and Context:\n",
    "A. Material Facts (key facts on which the case is based)\n",
    "B. Timeline (sequence of events leading up to and during the case)\n",
    "8. Case Outcome:\n",
    "A. Decision/Holding (the final judgment, such as \"Affirmed,\" \"Reversed\")\n",
    "B. Disposition (e.g., \"dismissed with prejudice,\" \"remanded\")\n",
    "C. Majority Opinion (summary or reasoning of the court's majority)\n",
    "D. Concurring Opinion (opinion agreeing with the majority but for different reasons)\n",
    "E. Dissenting Opinion (opinion disagreeing with the majority decision)\n",
    "9. Procedural History:\n",
    "A. Lower Court Rulings (previous decisions that led to the current case)\n",
    "B. Appeals (sequence of appeals, appellate court involvement)\n",
    "10. Relationships Between Entities:\n",
    "A. Case Citation Relationship (e.g., \"Case A cited Case B\")\n",
    "B. Statute Application (e.g., \"Statute X was applied in Case Y\")\n",
    "C. Fact Relationships (linking individuals or events to legal consequences)\n",
    "11. Court Documents:\n",
    "A. Pleadings (complaints, answers, motions)\n",
    "B. Briefs (e.g., appellate briefs, amicus briefs)\n",
    "C. Orders (e.g., summary judgment, dismissal orders)\n",
    "12. Dates:\n",
    "A. Date of Filing (date the case was initiated)\n",
    "B. Date of Decision (date the judgment was rendered)\n",
    "C. Hearing Dates (important hearings or oral argument dates)\n",
    "13. Legal Outcomes:\n",
    "A. Remedies (e.g., \"compensatory damages,\" \"injunctive relief\")\n",
    "B. Sentences (in criminal cases, e.g., \"5 years imprisonment\")\n",
    "14. Legal Concepts:\n",
    "A. Standards of Review (e.g., \"de novo,\" \"abuse of discretion\")\n",
    "B. Burden of Proof (e.g., \"preponderance of the evidence,\" \"beyond a reasonable doubt\")\n",
    "\n",
    "\n",
    "What are the entities of interest in the following text? Use the same numbering and lettering scheme as the entity categories above, using numbers for the major category of and letters for the minor category. \\n\\n{}\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract entities from each chunk of text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for chunk in chunks[:1]:\n",
    "    print(f\"Chunk of {chunk.metadata['id']}\")\n",
    "    response = model.invoke(query.format(chunk), max_tokens=1000)\n",
    "    print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
