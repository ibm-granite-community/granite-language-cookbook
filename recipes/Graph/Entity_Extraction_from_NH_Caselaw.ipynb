{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Entity Extraction from New Hampshire Case Law\n",
    "*With IBM Granite Models*\n",
    "\n",
    "The [New Hampshire Case Law Dataset](https://huggingface.co/datasets/free-law/nh) comes from the Caselaw Access Project via Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## In this notebook\n",
    "\n",
    "In this notebook, we'll explore the process of extracting meaningful information from text using entity extraction techniques, and then leverage that information to build and query a simple knowledge graph. Specifically, we'll guide you through the following steps:\n",
    "\n",
    "- **Entity Extraction**: We'll start by processing a body of text to identify and extract key entities, such as people, organizations, dates, and locations. Entity extraction is a crucial part of natural language processing (NLP) that helps in transforming raw text into structured data.\n",
    "- **Knowledge Graph Construction**: Once we've extracted entities, we'll build a basic knowledge graph. A knowledge graph represents entities as nodes and relationships as edges, providing a structured way to understand the interconnections between different entities within the text. This helps in visualizing and storing the extracted data meaningfully.\n",
    "- **Querying the Knowledge Graph**: With the knowledge graph in place, we can retrieve specific information by posing questions. We'll implement methods to query the graph, including resolving entities from the question to entities in the graph. This will allow us to identify relevant graph structures that correspond to the user's query.\n",
    "- **Question Answering**: Finally, we'll use the results retrieved from the knowledge graph to answer the user's question. By using the structured information from the graph, we can provide detailed answers and offer insights into the relationships and context within the body of text.\n",
    "\n",
    "This process of transforming unstructured text into a knowledge graph and then querying it is useful for applications such as legal research, medical case studies, or business intelligence. By the end of this notebook, you'll have hands-on experience building a simple pipeline that takes raw text, extracts valuable entities, and then allows users to query the data to obtain meaningful answers. Equipped with these techniques, we will move on to the more sophisticated techniques of Graph RAG."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "To get started, you'll need:\n",
    "* A [Replicate account](https://replicate.com/) and API token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Setting up the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Install dependencies\n",
    "\n",
    "Granite Kitchen comes with a bundle of dependencies that are required for notebooks. See the list of packages in its [`setup.py`](https://github.com/ibm-granite-community/granite-kitchen/blob/main/setup.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/ibm-granite-community/utils \\\n",
    "    langchain_community \\\n",
    "    replicate \\\n",
    "    datasets \\\n",
    "    transformers \\\n",
    "    tiktoken \\\n",
    "    neo4j \\\n",
    "    stringcase \\\n",
    "    langchain_huggingface \\\n",
    "    sentence-transformers \\\n",
    "    langchain_chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting System Components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Choose your LLM\n",
    "The LLM will be used for answering the question, given the retrieved text.\n",
    "\n",
    "Follow the instructions in [Getting Started with Replicate](https://github.com/ibm-granite-community/granite-kitchen/blob/cee1513c77429d7ddbf0e5a49b29b7bc9ca0d996/recipes/Getting_Started/Getting_Started_with_Replicate.ipynb), selecting a Granite Code model from the [`ibm-granite`](https://replicate.com/ibm-granite) org.\n",
    "\n",
    "To connect to a model on a provider other than Replicate, substitute this code cell with one from the [LLM component recipe](https://github.com/ibm-granite-community/granite-kitchen/blob/main/recipes/Components/Langchain_LLMs.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.llms import Replicate\n",
    "from ibm_granite_community.notebook_utils import set_env_var, get_env_var\n",
    "\n",
    "model = Replicate(\n",
    "    model=\"ibm-granite/granite-3.0-8b-instruct\",\n",
    "    replicate_api_token=get_env_var(\"REPLICATE_API_TOKEN\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the tokenizer\n",
    "\n",
    "Retrieve the tokenizer used by your chosen LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_path = \"ibm-granite/granite-3.0-8b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring the Data\n",
    "\n",
    "We will use a New Hampshire case law dataset to help the model answer questions about NH laws."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the documents\n",
    "\n",
    "Download the [New Hampshire CAP Caselaw](https://huggingface.co/datasets/free-law/nh) dataset from HuggingFace using the datasets library. Each document is a case; there should be about 21,540 of them in total. We will use a small subset in this recipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import HuggingFaceDatasetLoader\n",
    "\n",
    "# Load the documents from the dataset\n",
    "loader = HuggingFaceDatasetLoader(\"free-law/nh\", page_content_column=\"text\")\n",
    "all_documents = loader.load()\n",
    "print(\"Document Count: \" + str(len(all_documents)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the documents\n",
    "\n",
    "The documents contain case law text in their `page_content`, and metadata fields for the court name, decision date, and other information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in all_documents[:1]:\n",
    "    print(json.dumps(doc.metadata, indent=4), \"\\n\")\n",
    "    print(doc.page_content, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Extracting the entities\n",
    "\n",
    "In this example, we take the caselaw text, split it into chunks, and extract entities from each chunk. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the document into chunks\n",
    "\n",
    "Split the document into text chunks that can fit into the model's context window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import TokenTextSplitter\n",
    "\n",
    "doc_chunks = {}\n",
    "documents = [doc for doc in all_documents[:30] if doc.metadata[\"id\"] in ['4439812', '4439539', '4440694']]\n",
    "# documents = all_documents[:30]\n",
    "\n",
    "# Split the documents into chunks\n",
    "text_splitter = TokenTextSplitter(chunk_size=1000, chunk_overlap=50)\n",
    "for doc in documents:\n",
    "    id = doc.metadata[\"id\"]\n",
    "    chunks = text_splitter.split_documents([doc])\n",
    "    doc_chunks[id] = chunks\n",
    "    print(f\"Case {id}: \" + str(len(chunks)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in documents:\n",
    "    id = doc.metadata[\"id\"]\n",
    "    chunks = doc_chunks[id]\n",
    "    if len(chunks) > 0:\n",
    "        print(f\"Case {id}: \" + str(len(chunks)))\n",
    "        print(json.dumps(doc.metadata, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the chunks\n",
    "\n",
    "Each text chunk inherits the metadata from the document. For the purpose of this recipe, note that the `judge` is not well captured in many of these documents; we will be extracting it from the case law text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "for doc in documents[:10]:\n",
    "    id = doc.metadata[\"id\"]\n",
    "    print(json.dumps(doc.metadata, indent=4))\n",
    "    for chunk in doc_chunks[id]:\n",
    "        print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from this output that the \"judge\" in the metadata is not reliable, so we will pick that entity out of the text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify entity categories of interest\n",
    "\n",
    "For our example query, we will be interested in the judge and any precedent cited."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {\n",
    "    \"Counsel for Plaintiff/Petitioner\": \"The attorney or law firm representing the plaintiff/petitioner.\",\n",
    "    \"Counsel for Defendant/Respondent\": \"The attorney or law firm representing the defendant/respondent.\",\n",
    "    \"Judge/Justice\": \"The name of the judge or justice involved in the case, including their role (e.g., trial judge, appellate judge, presiding justice).\",\n",
    "    \"Statute/Act\": \"The statute or act referenced or applied in the case (e.g., 'Civil Rights Act of 1964').\",\n",
    "    \"Precedent Cited\": \"Previous case law referred to in the case.\",\n",
    "    \"Constitutional Provision\": \"The constitutional article or amendment referenced in the case (e.g., 'First Amendment,' 'Article III').\",\n",
    "    \"Decision/Holding\": \"The final judgment of the court (e.g., 'Affirmed,' 'Reversed').\",\n",
    "    \"Disposition\": \"The outcome of the case (e.g., 'dismissed with prejudice,' 'remanded').\",\n",
    "    \"Remedy\": \"Type of compensation or relief provided (e.g., 'compensatory damages,' 'injunctive relief').\",\n",
    "    \"Sentence\": \"In a criminal case, the sentence handed down (e.g., '5 years imprisonment').\"\n",
    "}\n",
    "\n",
    "categories_str = \"\\n\".join(f\"{k}: {v}\" for k, v in categories.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct a prompt template\n",
    "\n",
    "The template instructs the model to extract entities from a text. The list of entity categories is provided to guide the model's output, and ensure we are obtaining a pre-determined set of entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\\\n",
    "<|start_of_role|>system<|end_of_role|>\n",
    "Below is a list of entity categories:\n",
    "\n",
    "{categories_str}\n",
    "\n",
    "Given this list of entity categories, you will be asked to extract entities belonging to these categories from a text passage.\n",
    "Consider only the list of entity categories above; do not extract any additional entities. For each entity found, list the category and the entity, separated by a semicolon. Do not use the words \"Entity\" or \"Category\".\n",
    "\n",
    "Here are some examples:\n",
    "1. Remedy: Compensatory Damages\n",
    "2. Counsel for Defendant/Respondent: Jane C.\n",
    "3. Precedent Cited: State vs. Tiger\n",
    "<|end_of_text|>\n",
    "<|start_of_role|>user<|end_of_role|>\n",
    "Find the entities in the following text, and list them in the format specified above:\n",
    "\n",
    "{{}}\n",
    "<|end_of_text|>\n",
    "<|start_of_role|>assistant<|end_of_role|>\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract entities from each chunk of text\n",
    "\n",
    "The response will be a list of entities mentioned in each text chunk. Extraction takes about a minute for 10 documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_extracts = {}\n",
    "for doc in documents:\n",
    "    id = doc.metadata['id']\n",
    "    extracts = []\n",
    "    for i, chunk in enumerate(doc_chunks[id]):\n",
    "        print(f\"\\nChunk {i} of {id}\")\n",
    "        full_query = query.format(chunk.page_content)\n",
    "        print(str(len(tokenizer.tokenize(full_query))) + \" tokens\")\n",
    "        response = model.invoke(full_query, max_tokens=1000)\n",
    "        print(response)\n",
    "        extracts.append(response)\n",
    "\n",
    "    doc_extracts[id] = extracts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Graph Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Graph Triples\n",
    "\n",
    "Using the extracted entities along with the text chunk, construct graph triples. Graph triples are 3-tuples of subject, predicate, and object. In our recipe, they are 3-tuples of entity, role, and case.\n",
    "\n",
    "For ease of querying, in this recipe we use the entity name as the identifier for each entity. In a production system you would want to assign a unique ID to each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triples_from_extract(extract, case_name):\n",
    "    triples = []\n",
    "    lines = extract.splitlines()\n",
    "    for line in lines:\n",
    "        try:\n",
    "            # Take the number off of the front.\n",
    "            line = line.split(\". \", 1)[1]\n",
    "            role, entity = line.split(\": \", 2)\n",
    "            if role in categories:\n",
    "                triple = (entity, role, case_name)\n",
    "                triples.append(triple)\n",
    "        except (ValueError, IndexError):\n",
    "            print(f\"Error parsing case {id} line: {line}\")\n",
    "    return triples\n",
    "\n",
    "doc_triples = {}\n",
    "for doc in documents:\n",
    "    id = doc.metadata['id']\n",
    "    name = doc.metadata['name_abbreviation']\n",
    "    triples = []\n",
    "    for i, extract in enumerate(doc_extracts[id]):\n",
    "        # Break response up into entity triples.\n",
    "        new_triples = get_triples_from_extract(extract, name);\n",
    "        triples.extend(new_triples)\n",
    "    # Add triples from metadata.\n",
    "    triples.append((doc.metadata[\"court\"], 'Court', name))\n",
    "\n",
    "    # Add to triples for the document.\n",
    "    if id in doc_triples:\n",
    "        doc_triples[id].append(triples)\n",
    "    else:\n",
    "        doc_triples[id] = triples\n",
    "\n",
    "# Get all of the triples, filtering those that have no entity.\n",
    "all_triples = []\n",
    "for id, triples in doc_triples.items():\n",
    "    print(f\"Case {id}\")\n",
    "    for triple in triples:\n",
    "        e = triple[0].lower()\n",
    "        if \"not explicitly mentioned\" not in e \\\n",
    "            and \"not mentioned\" not in e \\\n",
    "            and \"not applicable\" not in e \\\n",
    "            and \"not specified\" not in e:\n",
    "            all_triples.append(triple)\n",
    "            print(triple)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neo4j import GraphDatabase\n",
    "from stringcase import snakecase, lowercase\n",
    "\n",
    "# Define the list of (entity, relationship, entity) triples\n",
    "triples = all_triples\n",
    "\n",
    "# Connect to the Neo4j database\n",
    "uri = get_env_var(\"NEO4J_URI\")\n",
    "username = get_env_var(\"NEO4J_USERNAME\")\n",
    "password = get_env_var(\"NEO4J_PASSWORD\")\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "def add_triple(tx, entity, role, case):\n",
    "    query = (\n",
    "        \"MERGE (e:Entity {name: $entity}) \"\n",
    "        \"MERGE (c:Case {name: $case}) \"\n",
    "        \"MERGE (e)-[r:%s]->(c)\"\n",
    "    ) % snakecase(lowercase(role.replace('/', '_')))\n",
    "    tx.run(query, entity=entity, case=case)\n",
    "\n",
    "def build_graph(triples):\n",
    "    with driver.session() as session:\n",
    "        # Empty the graph first\n",
    "        session.run(\"MATCH (n) DETACH DELETE n\")\n",
    "        # Fill the graph\n",
    "        for entity, role, case in triples:\n",
    "            session.write_transaction(add_triple, entity, role, case)\n",
    "\n",
    "# Build the graph from the triples list\n",
    "build_graph(triples)\n",
    "\n",
    "# Close the connection to the database\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the contents of the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    # Query to find all nodes\n",
    "    result = session.run(\"MATCH (n) RETURN n.name AS name\")\n",
    "    print(\"Nodes in the graph:\")\n",
    "    for record in result:\n",
    "        print(record[\"name\"])\n",
    "\n",
    "    # Query to find all relationships\n",
    "    result = session.run(\"MATCH ()-[r]->() RETURN type(r) AS rel\")\n",
    "    print(\"\\nRelationship types in the graph:\")\n",
    "    rels = [record[\"rel\"] for record in result]\n",
    "    # unique rels\n",
    "    rels = list(set(rels))\n",
    "    for rel in rels:\n",
    "        print(rel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find all precedents cited in the graph\n",
    "\n",
    "As an example of how we can now use the graph, we will find all precedents cited in the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "with driver.session() as session:\n",
    "    # Query to find all nodes\n",
    "    result = session.run(\"MATCH (a)-[:precedent_cited]->() RETURN a.name AS name\")\n",
    "    print(\"Precedents in the graph:\")\n",
    "    for record in result:\n",
    "        print(record[\"name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate a vector database with entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "embeddings_model = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_chroma import Chroma\n",
    "\n",
    "vector_db = Chroma(embedding_function=embeddings_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add graph nodes to the vector database.\n",
    "\n",
    "For the purpose of illustration, we will add embeddings of the entity names, which are also used as entity keys in the vector database. A more sophisticated aproach would be to generate descriptions of the entities and embed those instead, capturing more context and nuance about the entity indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.docstore.document import Document\n",
    "names = []\n",
    "with driver.session() as session:\n",
    "    # Query to find all nodes\n",
    "    result = session.run(\"MATCH (e)-[r]->() RETURN e.name AS entity, type(r) AS role\")\n",
    "    for record in result:\n",
    "        doc = Document(page_content=f\"{record['entity']} is a {record['role']}\", metadata={\"entity\": record[\"entity\"]})\n",
    "        names.append(doc)\n",
    "\n",
    "ids = vector_db.add_documents(names)\n",
    "print(\"Documents added: \", len(ids))\n",
    "doc_count = len(vector_db._collection.get(include=[\"documents\"])[\"documents\"])\n",
    "print(\"Documents total: \", doc_count)\n",
    "# vector_db.delete_collection()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract entities from question\n",
    "\n",
    "This is one type of question that can be asked. It mentions two entities of interest, `Judge Bois` (a judge), and `Durkin v. Snow` (a case used as precedent). To answer the question, we will find cases that have these two entities in common."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"How has Judge Bois used Durkin v. Snow to rule on cases?\"\n",
    "\n",
    "response = model.invoke(query.format(question))\n",
    "print(response)\n",
    "question_entity_triples = get_triples_from_extract(response, \"\")\n",
    "print(question_entity_triples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match entities to the graph\n",
    "\n",
    "We match the question entities to entities in the graph, in order to create a graph query for related cases. We match on a short description of the entity using its role, as extracted from both the question and the case text. This is done by comparing the embeddings of each description for proximity in the semantic embedding space created by the embeddings model. To improve the performance of this match, we could additional context from the question and the case, and even the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def match_entity(entity, threshold=1.0):\n",
    "    \"\"\"Match entities by embedding vector distance given a similarity threshold. With Chroma, l2 (Euclidean) distance is used.\"\"\"\n",
    "    docs_with_score = vector_db.similarity_search_with_score(entity, k=5)\n",
    "    for doc, score in docs_with_score:\n",
    "        print(f\"{doc.metadata['entity']} -- similarity score {score}\")\n",
    "        next\n",
    "    if len(docs_with_score):\n",
    "        doc, score = docs_with_score[0]\n",
    "        if score <= threshold:\n",
    "            # Return first close match.\n",
    "            return doc.metadata[\"entity\"]\n",
    "    else:\n",
    "        # No match.\n",
    "        return None\n",
    "\n",
    "for triple in question_entity_triples:\n",
    "    entity = triple[0]\n",
    "    entity_desc = f\"{triple[0]} is a {triple[1]}.\"\n",
    "    print(f\"\\nMatching {entity}\")\n",
    "    match = match_entity(entity_desc)\n",
    "    if match is not None:\n",
    "        print(f\"Match: {match}\")\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query the graph for cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for cases given a single entity and its relationship to the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_for_cases(entity_name, role):\n",
    "    with driver.session() as session:\n",
    "        relationship = snakecase(lowercase(role.replace('/', '_')))\n",
    "        query = f\"MATCH (e:Entity {{name: '{entity_name}'}})-[:{relationship}]->(c:Case) RETURN c.name AS name\"\n",
    "        print(query)\n",
    "        result = session.run(query)\n",
    "        print(\"Cases:\")\n",
    "        for record in result:\n",
    "            print(record[\"name\"])\n",
    "\n",
    "for triple in question_entity_triples:\n",
    "    entity, role, case = triple\n",
    "    entity_match = match_entity(entity)\n",
    "    query_for_cases(entity_match, role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Query for cases given multiple entities and their relationships to the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_for_cases(entity_role_pairs):\n",
    "    with driver.session() as session:\n",
    "        query = \"\"\n",
    "        for i, (entity, role) in enumerate(entity_role_pairs):\n",
    "            relationship = snakecase(lowercase(role.replace('/', '_')))\n",
    "            query += f\"MATCH (e{str(i)}:Entity {{name: '{entity}'}})-[:{relationship}]->(c)\\n\"\n",
    "        query += \"RETURN c.name AS name\"\n",
    "        print(query)\n",
    "        result = session.run(query)\n",
    "        cases = []\n",
    "        print(\"Cases:\")\n",
    "        for record in result:\n",
    "            cases.append(record[\"name\"])\n",
    "            print(record[\"name\"])\n",
    "        return cases\n",
    "\n",
    "entity_role_pairs = []\n",
    "for triple in question_entity_triples:\n",
    "    entity, role, case = triple\n",
    "    entity_match = match_entity(entity)\n",
    "    entity_role_pairs.append((entity_match, role))\n",
    "    \n",
    "cases = query_for_cases(entity_role_pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieve the case text\n",
    "\n",
    "We have found a case related to both entities in the question. Let's retrieve the case text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "case_text = [doc.page_content for doc in documents if doc.metadata[\"name_abbreviation\"] == cases[0]][0]\n",
    "print(case_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer the question\n",
    "\n",
    "Having retrieved the case text, now let's answer the question given the case text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = f\"\"\"\n",
    "Answer the question using the following text from one case: \\n\\n{case_text}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "print(question)\n",
    "response = model.invoke(q)\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
